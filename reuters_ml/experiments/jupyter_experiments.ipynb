{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a53b5060-5f98-46e5-b0cd-5051fbb34fb0",
   "metadata": {},
   "source": [
    "# 1. Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6187dd4-bc7d-4f73-8612-6a278f10420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "from typing import Dict\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "STOP_WORDS = \"stop_words.txt\"\n",
    "TRAIN_DATA = \"reuters_train.csv\"\n",
    "TEST_DATA = \"reuters_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c062795-33d9-4b30-96d7-127c2ecbbe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(test_labels: np.ndarray, \n",
    "                      pred_labels: np.ndarray, \n",
    "                      average='samples') -> None:\n",
    "    print(\n",
    "        f\"Precision: {precision_score(test_labels, pred_labels, average=average)}, \\n\", \\\n",
    "        f\"Recall: {recall_score(test_labels, pred_labels, average=average)}, \\n\", \\\n",
    "        f\"F1 Measure: {f1_score(test_labels, pred_labels, average=average)}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b79b69e-332d-4f47-9574-3190e99b6355",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(STOP_WORDS) as file:\n",
    "    stop_words = [line.rstrip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cf01d5f-9d9a-42eb-bf9b-b3d155a15ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(TRAIN_DATA)\n",
    "df_train.labels = df_train.labels.apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55754c0b-292e-41cc-8b7c-9d6dd2fccd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(TEST_DATA)\n",
    "df_test.labels = df_test.labels.apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "759faa6f-06e5-4078-9ba9-d28bb3fccbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "train_labels = mlb.fit_transform(df_train.labels)\n",
    "test_labels = mlb.transform(df_test.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecc8c5b-b681-44a4-8ce7-a8aeda2e58c6",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c086a63-c16d-4b3c-92e4-164cc6b68742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "def preprocess(text: str) -> str:\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    # text = re.sub('(?<=\\d),(?=\\d)', '', text)  # removing comma symbol between numbers\n",
    "    # text = re.sub(r\"[^\\w\\d,\\s]+\",'',text)  # cleaning punktuation\n",
    "    tokens = text.split()  # split string into tokens by WhiteSpace\n",
    "    tokens = [t for t in tokens if t.isalpha()]  # removing numbers and symbols from string\n",
    "    tokens = [t for t in tokens if t not in stop_words]  # remove stopwords\n",
    "    text = \" \".join(tokens).lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90dc7a6f-1291-4625-a269-03fa3df25e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"content_prep\"] = df_train[\"content\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fca4bd70-ecf1-43b2-a722-a541e40b56d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"content_prep\"] = df_test[\"content\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "918acf13-5a0b-47c1-ae70-3ba025af8283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(column_name: str = \"content\",\n",
    "                train_data: pd.DataFrame = df_train, \n",
    "                test_data: pd.DataFrame = df_test) -> Dict[str, csr_matrix]:\n",
    "    vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "    \n",
    "    vectorised_train = vectorizer.fit_transform(train_data[column_name])\n",
    "    vectorised_test = vectorizer.transform(test_data[column_name])\n",
    "    return {\"train\": vectorised_train, \"test\": vectorised_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62247bd8-d3b9-4e6b-af98-a1c621a21f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = get_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33524534-4977-4001-a1c6-f7f22c66e0f7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'content_prep'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m/opt/jupyter/lib64/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3620\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3621\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3622\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m/opt/jupyter/lib64/python3.8/site-packages/pandas/_libs/index.pyx:136\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/opt/jupyter/lib64/python3.8/site-packages/pandas/_libs/index.pyx:163\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'content_prep'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[0;32mIn [9]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m vectors_prep \u001B[38;5;241m=\u001B[39m \u001B[43mget_vectors\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcolumn_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcontent_prep\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36mget_vectors\u001B[0;34m(column_name, train_data, test_data)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_vectors\u001B[39m(column_name: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m, \n\u001B[1;32m      2\u001B[0m                 train_data: pd\u001B[38;5;241m.\u001B[39mDataFrame \u001B[38;5;241m=\u001B[39m df_train, \n\u001B[1;32m      3\u001B[0m                 test_data: pd\u001B[38;5;241m.\u001B[39mDataFrame \u001B[38;5;241m=\u001B[39m df_test) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, csr_matrix]:\n\u001B[1;32m      4\u001B[0m     vectorizer \u001B[38;5;241m=\u001B[39m TfidfVectorizer(stop_words\u001B[38;5;241m=\u001B[39mstop_words)\n\u001B[0;32m----> 6\u001B[0m     vectorised_train \u001B[38;5;241m=\u001B[39m vectorizer\u001B[38;5;241m.\u001B[39mfit_transform(\u001B[43mtrain_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcolumn_name\u001B[49m\u001B[43m]\u001B[49m)\n\u001B[1;32m      7\u001B[0m     vectorised_test \u001B[38;5;241m=\u001B[39m vectorizer\u001B[38;5;241m.\u001B[39mtransform(test_data[column_name])\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m: vectorised_train, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m\"\u001B[39m: vectorised_test}\n",
      "File \u001B[0;32m/opt/jupyter/lib64/python3.8/site-packages/pandas/core/frame.py:3505\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3503\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3504\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3505\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3507\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m/opt/jupyter/lib64/python3.8/site-packages/pandas/core/indexes/base.py:3623\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3621\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3622\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3623\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3624\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3625\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3626\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3627\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3628\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'content_prep'"
     ]
    }
   ],
   "source": [
    "vectors_prep = get_vectors(column_name=\"content_prep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65a9536-d9c7-4743-9891-5a4728116f27",
   "metadata": {},
   "source": [
    "# 3.Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5332cdd0-2be3-46a6-bf63-3803f54b08b6",
   "metadata": {},
   "source": [
    "## 3.1 LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b12b7e7a-3e64-44a0-ab4c-927f1fd846ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, \n",
    "                train_vectors, \n",
    "                test_vectors, \n",
    "                train_labels=train_labels,\n",
    "                test_labels=test_labels,\n",
    "                *args, **kwargs):\n",
    "    classifier = OneVsRestClassifier(model(*args, **kwargs))\n",
    "    classifier.fit(train_vectors, train_labels)\n",
    "\n",
    "    predictions = classifier.predict(test_vectors)\n",
    "    calculate_metrics(test_labels, pred_labels=predictions)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "957b3e09-7f93-4cef-96fd-87c22ff60477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8799287055000867, \n",
      " Recall: 0.8616793496886243, \n",
      " F1 Measure: 0.862993617291398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyter/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "svc = train_model(LinearSVC, \n",
    "                train_vectors=vectors[\"train\"], \n",
    "                test_vectors=vectors[\"test\"], \n",
    "                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d753e15e-7784-4ca3-a79d-0d870e4aa8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.876592690736447, \n",
      " Recall: 0.8583610677350325, \n",
      " F1 Measure: 0.8595997990085437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyter/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "svc_prep = train_model(LinearSVC, \n",
    "                train_vectors=vectors_prep[\"train\"], \n",
    "                test_vectors=vectors_prep[\"test\"], \n",
    "                random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648e1d3d-f60b-452f-8a82-6b31914634dd",
   "metadata": {},
   "source": [
    "## 3.2 KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "77c75e03-018a-4826-ada1-f9fac7f0dbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8068455338412278, \n",
      " Recall: 0.7979560785539587, \n",
      " F1 Measure: 0.7935620137839415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyter/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "knn = train_model(KNeighborsClassifier, \n",
    "                train_vectors=vectors[\"train\"], \n",
    "                test_vectors=vectors[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "90f34e65-3f80-4bc8-9231-7f9b1bfc33e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3890250634868058, \n",
      " Recall: 0.38808656287954063, \n",
      " F1 Measure: 0.38729186054459325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyter/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "knn_prep = train_model(KNeighborsClassifier, \n",
    "                train_vectors=vectors_prep[\"train\"], \n",
    "                test_vectors=vectors_prep[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21fbd1e-ddc5-46f3-bd25-b21d3595326f",
   "metadata": {},
   "source": [
    "Metrics using preprocessing look worse than basic data, will not use preprocessing further"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc3a152-aebc-4d66-9527-83f3f398c8ca",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6eeaca-dd10-432e-9487-6647fc6c45f8",
   "metadata": {},
   "source": [
    "## 3.3 Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "001c0380-b5f2-49e0-a080-52c8eef103ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool = Pool(vectors[\"train\"], train_labels)\n",
    "test_pool = Pool(vectors[\"test\"], test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c98b07a3-b1ad-4301-81a1-30d4d00f1653",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.071085\n",
      "0:\tlearn: 0.0136697\ttest: 0.0137684\tbest: 0.0137684 (0)\ttotal: 8.98s\tremaining: 1h 14m 39s\n",
      "1:\tlearn: 0.0136783\ttest: 0.0137573\tbest: 0.0137573 (1)\ttotal: 17.9s\tremaining: 1h 14m 9s\n",
      "2:\tlearn: 0.0115516\ttest: 0.0106253\tbest: 0.0106253 (2)\ttotal: 26.7s\tremaining: 1h 13m 47s\n",
      "3:\tlearn: 0.0116989\ttest: 0.0107357\tbest: 0.0106253 (2)\ttotal: 35.6s\tremaining: 1h 13m 31s\n",
      "4:\tlearn: 0.0114658\ttest: 0.0107099\tbest: 0.0106253 (2)\ttotal: 44.4s\tremaining: 1h 13m 19s\n",
      "5:\tlearn: 0.0115044\ttest: 0.0105443\tbest: 0.0105443 (5)\ttotal: 53.3s\tremaining: 1h 13m 10s\n",
      "6:\tlearn: 0.0114329\ttest: 0.0105149\tbest: 0.0105149 (6)\ttotal: 1m 2s\tremaining: 1h 12m 56s\n",
      "7:\tlearn: 0.0109095\ttest: 0.0103493\tbest: 0.0103493 (7)\ttotal: 1m 10s\tremaining: 1h 12m 40s\n",
      "8:\tlearn: 0.0107521\ttest: 0.0103125\tbest: 0.0103125 (8)\ttotal: 1m 19s\tremaining: 1h 12m 27s\n",
      "9:\tlearn: 0.0107049\ttest: 0.0102646\tbest: 0.0102646 (9)\ttotal: 1m 28s\tremaining: 1h 12m 15s\n",
      "10:\tlearn: 0.0107679\ttest: 0.0102757\tbest: 0.0102646 (9)\ttotal: 1m 37s\tremaining: 1h 12m 3s\n",
      "11:\tlearn: 0.0105705\ttest: 0.0102315\tbest: 0.0102315 (11)\ttotal: 1m 46s\tremaining: 1h 11m 51s\n",
      "12:\tlearn: 0.0104361\ttest: 0.0101468\tbest: 0.0101468 (12)\ttotal: 1m 54s\tremaining: 1h 11m 40s\n",
      "13:\tlearn: 0.0102344\ttest: 0.0099739\tbest: 0.0099739 (13)\ttotal: 2m 3s\tremaining: 1h 11m 33s\n",
      "14:\tlearn: 0.0101386\ttest: 0.0098598\tbest: 0.0098598 (14)\ttotal: 2m 12s\tremaining: 1h 11m 23s\n",
      "15:\tlearn: 0.0100900\ttest: 0.0098230\tbest: 0.0098230 (15)\ttotal: 2m 21s\tremaining: 1h 11m 13s\n",
      "16:\tlearn: 0.0098397\ttest: 0.0094991\tbest: 0.0094991 (16)\ttotal: 2m 30s\tremaining: 1h 11m 19s\n",
      "17:\tlearn: 0.0095136\ttest: 0.0091863\tbest: 0.0091863 (17)\ttotal: 2m 39s\tremaining: 1h 11m 8s\n",
      "18:\tlearn: 0.0094507\ttest: 0.0091016\tbest: 0.0091016 (18)\ttotal: 2m 48s\tremaining: 1h 10m 58s\n",
      "19:\tlearn: 0.0091560\ttest: 0.0087961\tbest: 0.0087961 (19)\ttotal: 2m 57s\tremaining: 1h 10m 48s\n",
      "20:\tlearn: 0.0090030\ttest: 0.0086268\tbest: 0.0086268 (20)\ttotal: 3m 5s\tremaining: 1h 10m 38s\n",
      "21:\tlearn: 0.0089630\ttest: 0.0085716\tbest: 0.0085716 (21)\ttotal: 3m 14s\tremaining: 1h 10m 30s\n",
      "22:\tlearn: 0.0089201\ttest: 0.0085643\tbest: 0.0085643 (22)\ttotal: 3m 23s\tremaining: 1h 10m 21s\n",
      "23:\tlearn: 0.0086984\ttest: 0.0083729\tbest: 0.0083729 (23)\ttotal: 3m 32s\tremaining: 1h 10m 10s\n",
      "24:\tlearn: 0.0085911\ttest: 0.0082846\tbest: 0.0082846 (24)\ttotal: 3m 41s\tremaining: 1h 10m\n",
      "25:\tlearn: 0.0084524\ttest: 0.0082220\tbest: 0.0082220 (25)\ttotal: 3m 49s\tremaining: 1h 9m 51s\n",
      "26:\tlearn: 0.0083837\ttest: 0.0081594\tbest: 0.0081594 (26)\ttotal: 3m 58s\tremaining: 1h 9m 41s\n",
      "27:\tlearn: 0.0083623\ttest: 0.0081447\tbest: 0.0081447 (27)\ttotal: 4m 7s\tremaining: 1h 9m 31s\n",
      "28:\tlearn: 0.0082836\ttest: 0.0081005\tbest: 0.0081005 (28)\ttotal: 4m 16s\tremaining: 1h 9m 22s\n",
      "29:\tlearn: 0.0082350\ttest: 0.0080858\tbest: 0.0080858 (29)\ttotal: 4m 25s\tremaining: 1h 9m 12s\n",
      "30:\tlearn: 0.0080763\ttest: 0.0079901\tbest: 0.0079901 (30)\ttotal: 4m 33s\tremaining: 1h 9m 2s\n",
      "31:\tlearn: 0.0079590\ttest: 0.0078724\tbest: 0.0078724 (31)\ttotal: 4m 42s\tremaining: 1h 8m 52s\n",
      "32:\tlearn: 0.0077702\ttest: 0.0077840\tbest: 0.0077840 (32)\ttotal: 4m 51s\tremaining: 1h 8m 42s\n",
      "33:\tlearn: 0.0076715\ttest: 0.0076663\tbest: 0.0076663 (33)\ttotal: 5m\tremaining: 1h 8m 33s\n",
      "34:\tlearn: 0.0076186\ttest: 0.0076147\tbest: 0.0076147 (34)\ttotal: 5m 8s\tremaining: 1h 8m 24s\n",
      "35:\tlearn: 0.0075528\ttest: 0.0075779\tbest: 0.0075779 (35)\ttotal: 5m 17s\tremaining: 1h 8m 14s\n",
      "36:\tlearn: 0.0074756\ttest: 0.0074749\tbest: 0.0074749 (36)\ttotal: 5m 26s\tremaining: 1h 8m 5s\n",
      "37:\tlearn: 0.0074098\ttest: 0.0074638\tbest: 0.0074638 (37)\ttotal: 5m 35s\tremaining: 1h 7m 55s\n",
      "38:\tlearn: 0.0073240\ttest: 0.0074160\tbest: 0.0074160 (38)\ttotal: 5m 43s\tremaining: 1h 7m 45s\n",
      "39:\tlearn: 0.0072425\ttest: 0.0073424\tbest: 0.0073424 (39)\ttotal: 5m 52s\tremaining: 1h 7m 35s\n",
      "40:\tlearn: 0.0071853\ttest: 0.0072504\tbest: 0.0072504 (40)\ttotal: 6m 1s\tremaining: 1h 7m 27s\n",
      "41:\tlearn: 0.0070308\ttest: 0.0071731\tbest: 0.0071731 (41)\ttotal: 6m 10s\tremaining: 1h 7m 17s\n",
      "42:\tlearn: 0.0070065\ttest: 0.0071768\tbest: 0.0071731 (41)\ttotal: 6m 19s\tremaining: 1h 7m 8s\n",
      "43:\tlearn: 0.0069335\ttest: 0.0070921\tbest: 0.0070921 (43)\ttotal: 6m 27s\tremaining: 1h 6m 58s\n",
      "44:\tlearn: 0.0068806\ttest: 0.0070737\tbest: 0.0070737 (44)\ttotal: 6m 36s\tremaining: 1h 6m 49s\n",
      "45:\tlearn: 0.0068291\ttest: 0.0070406\tbest: 0.0070406 (45)\ttotal: 6m 45s\tremaining: 1h 6m 39s\n",
      "46:\tlearn: 0.0067376\ttest: 0.0069670\tbest: 0.0069670 (46)\ttotal: 6m 54s\tremaining: 1h 6m 30s\n",
      "47:\tlearn: 0.0067061\ttest: 0.0069633\tbest: 0.0069633 (47)\ttotal: 7m 2s\tremaining: 1h 6m 21s\n",
      "48:\tlearn: 0.0066332\ttest: 0.0068971\tbest: 0.0068971 (48)\ttotal: 7m 11s\tremaining: 1h 6m 12s\n",
      "49:\tlearn: 0.0065789\ttest: 0.0068308\tbest: 0.0068308 (49)\ttotal: 7m 20s\tremaining: 1h 6m 3s\n",
      "50:\tlearn: 0.0065202\ttest: 0.0068198\tbest: 0.0068198 (50)\ttotal: 7m 29s\tremaining: 1h 5m 54s\n",
      "51:\tlearn: 0.0064873\ttest: 0.0067903\tbest: 0.0067903 (51)\ttotal: 7m 37s\tremaining: 1h 5m 45s\n",
      "52:\tlearn: 0.0064516\ttest: 0.0067756\tbest: 0.0067756 (52)\ttotal: 7m 46s\tremaining: 1h 5m 36s\n",
      "53:\tlearn: 0.0064001\ttest: 0.0067388\tbest: 0.0067388 (53)\ttotal: 7m 55s\tremaining: 1h 5m 27s\n",
      "54:\tlearn: 0.0063686\ttest: 0.0067130\tbest: 0.0067130 (54)\ttotal: 8m 4s\tremaining: 1h 5m 18s\n",
      "55:\tlearn: 0.0063400\ttest: 0.0066762\tbest: 0.0066762 (55)\ttotal: 8m 13s\tremaining: 1h 5m 9s\n",
      "56:\tlearn: 0.0062757\ttest: 0.0066210\tbest: 0.0066210 (56)\ttotal: 8m 21s\tremaining: 1h 5m\n",
      "57:\tlearn: 0.0062127\ttest: 0.0065879\tbest: 0.0065879 (57)\ttotal: 8m 30s\tremaining: 1h 4m 51s\n",
      "58:\tlearn: 0.0061813\ttest: 0.0065474\tbest: 0.0065474 (58)\ttotal: 8m 39s\tremaining: 1h 4m 42s\n",
      "59:\tlearn: 0.0061541\ttest: 0.0065327\tbest: 0.0065327 (59)\ttotal: 8m 48s\tremaining: 1h 4m 33s\n",
      "60:\tlearn: 0.0060983\ttest: 0.0065033\tbest: 0.0065033 (60)\ttotal: 8m 56s\tremaining: 1h 4m 24s\n",
      "61:\tlearn: 0.0060454\ttest: 0.0065069\tbest: 0.0065033 (60)\ttotal: 9m 5s\tremaining: 1h 4m 15s\n",
      "62:\tlearn: 0.0060139\ttest: 0.0064812\tbest: 0.0064812 (62)\ttotal: 9m 14s\tremaining: 1h 4m 6s\n",
      "63:\tlearn: 0.0059839\ttest: 0.0064701\tbest: 0.0064701 (63)\ttotal: 9m 23s\tremaining: 1h 3m 58s\n",
      "64:\tlearn: 0.0059682\ttest: 0.0064517\tbest: 0.0064517 (64)\ttotal: 9m 32s\tremaining: 1h 3m 49s\n",
      "65:\tlearn: 0.0059295\ttest: 0.0064186\tbest: 0.0064186 (65)\ttotal: 9m 41s\tremaining: 1h 3m 41s\n",
      "66:\tlearn: 0.0058981\ttest: 0.0063965\tbest: 0.0063965 (66)\ttotal: 9m 49s\tremaining: 1h 3m 32s\n",
      "67:\tlearn: 0.0058781\ttest: 0.0063818\tbest: 0.0063818 (67)\ttotal: 9m 58s\tremaining: 1h 3m 23s\n",
      "68:\tlearn: 0.0058652\ttest: 0.0063524\tbest: 0.0063524 (68)\ttotal: 10m 7s\tremaining: 1h 3m 15s\n",
      "69:\tlearn: 0.0058537\ttest: 0.0063266\tbest: 0.0063266 (69)\ttotal: 10m 16s\tremaining: 1h 3m 6s\n",
      "70:\tlearn: 0.0058337\ttest: 0.0062861\tbest: 0.0062861 (70)\ttotal: 10m 25s\tremaining: 1h 2m 57s\n",
      "71:\tlearn: 0.0058123\ttest: 0.0062788\tbest: 0.0062788 (71)\ttotal: 10m 33s\tremaining: 1h 2m 48s\n",
      "72:\tlearn: 0.0057822\ttest: 0.0062346\tbest: 0.0062346 (72)\ttotal: 10m 42s\tremaining: 1h 2m 40s\n",
      "73:\tlearn: 0.0057379\ttest: 0.0062125\tbest: 0.0062125 (73)\ttotal: 10m 51s\tremaining: 1h 2m 31s\n",
      "74:\tlearn: 0.0057179\ttest: 0.0061867\tbest: 0.0061867 (74)\ttotal: 11m\tremaining: 1h 2m 22s\n",
      "75:\tlearn: 0.0056979\ttest: 0.0061831\tbest: 0.0061831 (75)\ttotal: 11m 9s\tremaining: 1h 2m 13s\n",
      "76:\tlearn: 0.0056735\ttest: 0.0061757\tbest: 0.0061757 (76)\ttotal: 11m 17s\tremaining: 1h 2m 4s\n",
      "77:\tlearn: 0.0056578\ttest: 0.0061647\tbest: 0.0061647 (77)\ttotal: 11m 26s\tremaining: 1h 1m 55s\n",
      "78:\tlearn: 0.0056235\ttest: 0.0061426\tbest: 0.0061426 (78)\ttotal: 11m 35s\tremaining: 1h 1m 46s\n",
      "79:\tlearn: 0.0056049\ttest: 0.0061573\tbest: 0.0061426 (78)\ttotal: 11m 44s\tremaining: 1h 1m 36s\n",
      "80:\tlearn: 0.0055691\ttest: 0.0061426\tbest: 0.0061426 (78)\ttotal: 11m 52s\tremaining: 1h 1m 27s\n",
      "81:\tlearn: 0.0055420\ttest: 0.0061242\tbest: 0.0061242 (81)\ttotal: 12m 1s\tremaining: 1h 1m 18s\n",
      "82:\tlearn: 0.0054776\ttest: 0.0060874\tbest: 0.0060874 (82)\ttotal: 12m 10s\tremaining: 1h 1m 9s\n",
      "83:\tlearn: 0.0054404\ttest: 0.0060616\tbest: 0.0060616 (83)\ttotal: 12m 19s\tremaining: 1h 1m\n",
      "84:\tlearn: 0.0054233\ttest: 0.0060358\tbest: 0.0060358 (84)\ttotal: 12m 28s\tremaining: 1h 52s\n",
      "85:\tlearn: 0.0054004\ttest: 0.0060358\tbest: 0.0060358 (84)\ttotal: 12m 36s\tremaining: 1h 43s\n",
      "86:\tlearn: 0.0053746\ttest: 0.0060322\tbest: 0.0060322 (86)\ttotal: 12m 45s\tremaining: 1h 34s\n",
      "87:\tlearn: 0.0053460\ttest: 0.0060174\tbest: 0.0060174 (87)\ttotal: 12m 54s\tremaining: 1h 25s\n",
      "88:\tlearn: 0.0053189\ttest: 0.0060064\tbest: 0.0060064 (88)\ttotal: 13m 3s\tremaining: 1h 16s\n",
      "89:\tlearn: 0.0052674\ttest: 0.0059659\tbest: 0.0059659 (89)\ttotal: 13m 11s\tremaining: 1h 7s\n",
      "90:\tlearn: 0.0052531\ttest: 0.0059696\tbest: 0.0059659 (89)\ttotal: 13m 20s\tremaining: 59m 58s\n",
      "91:\tlearn: 0.0052087\ttest: 0.0059402\tbest: 0.0059402 (91)\ttotal: 13m 29s\tremaining: 59m 49s\n",
      "92:\tlearn: 0.0051773\ttest: 0.0059218\tbest: 0.0059218 (92)\ttotal: 13m 38s\tremaining: 59m 40s\n",
      "93:\tlearn: 0.0051487\ttest: 0.0059218\tbest: 0.0059218 (92)\ttotal: 13m 46s\tremaining: 59m 31s\n",
      "94:\tlearn: 0.0051015\ttest: 0.0058923\tbest: 0.0058923 (94)\ttotal: 13m 55s\tremaining: 59m 23s\n",
      "95:\tlearn: 0.0050686\ttest: 0.0058629\tbest: 0.0058629 (95)\ttotal: 14m 4s\tremaining: 59m 14s\n",
      "96:\tlearn: 0.0050200\ttest: 0.0058408\tbest: 0.0058408 (96)\ttotal: 14m 13s\tremaining: 59m 5s\n",
      "97:\tlearn: 0.0049799\ttest: 0.0058113\tbest: 0.0058113 (97)\ttotal: 14m 22s\tremaining: 58m 56s\n",
      "98:\tlearn: 0.0049499\ttest: 0.0058040\tbest: 0.0058040 (98)\ttotal: 14m 30s\tremaining: 58m 47s\n",
      "99:\tlearn: 0.0049227\ttest: 0.0057893\tbest: 0.0057893 (99)\ttotal: 14m 39s\tremaining: 58m 38s\n",
      "100:\tlearn: 0.0048812\ttest: 0.0057782\tbest: 0.0057782 (100)\ttotal: 14m 48s\tremaining: 58m 29s\n",
      "101:\tlearn: 0.0048598\ttest: 0.0057672\tbest: 0.0057672 (101)\ttotal: 14m 57s\tremaining: 58m 20s\n",
      "102:\tlearn: 0.0048297\ttest: 0.0057561\tbest: 0.0057561 (102)\ttotal: 15m 5s\tremaining: 58m 12s\n",
      "103:\tlearn: 0.0047997\ttest: 0.0057120\tbest: 0.0057120 (103)\ttotal: 15m 14s\tremaining: 58m 3s\n",
      "104:\tlearn: 0.0047682\ttest: 0.0057120\tbest: 0.0057120 (103)\ttotal: 15m 23s\tremaining: 57m 54s\n",
      "105:\tlearn: 0.0047411\ttest: 0.0056936\tbest: 0.0056936 (105)\ttotal: 15m 32s\tremaining: 57m 45s\n",
      "106:\tlearn: 0.0047153\ttest: 0.0056678\tbest: 0.0056678 (106)\ttotal: 15m 41s\tremaining: 57m 37s\n",
      "107:\tlearn: 0.0046967\ttest: 0.0056678\tbest: 0.0056678 (106)\ttotal: 15m 50s\tremaining: 57m 28s\n",
      "108:\tlearn: 0.0046567\ttest: 0.0056604\tbest: 0.0056604 (108)\ttotal: 15m 58s\tremaining: 57m 19s\n",
      "109:\tlearn: 0.0046267\ttest: 0.0056531\tbest: 0.0056531 (109)\ttotal: 16m 7s\tremaining: 57m 11s\n",
      "110:\tlearn: 0.0045952\ttest: 0.0056384\tbest: 0.0056384 (110)\ttotal: 16m 16s\tremaining: 57m 2s\n",
      "111:\tlearn: 0.0045723\ttest: 0.0056384\tbest: 0.0056384 (110)\ttotal: 16m 25s\tremaining: 56m 53s\n",
      "112:\tlearn: 0.0045423\ttest: 0.0056089\tbest: 0.0056089 (112)\ttotal: 16m 34s\tremaining: 56m 45s\n",
      "113:\tlearn: 0.0045094\ttest: 0.0055758\tbest: 0.0055758 (113)\ttotal: 16m 43s\tremaining: 56m 36s\n",
      "114:\tlearn: 0.0044936\ttest: 0.0055758\tbest: 0.0055758 (113)\ttotal: 16m 51s\tremaining: 56m 27s\n",
      "115:\tlearn: 0.0044650\ttest: 0.0055500\tbest: 0.0055500 (115)\ttotal: 17m\tremaining: 56m 18s\n",
      "116:\tlearn: 0.0044550\ttest: 0.0055464\tbest: 0.0055464 (116)\ttotal: 17m 9s\tremaining: 56m 10s\n",
      "117:\tlearn: 0.0044221\ttest: 0.0055059\tbest: 0.0055059 (117)\ttotal: 17m 18s\tremaining: 56m 1s\n",
      "118:\tlearn: 0.0043964\ttest: 0.0055096\tbest: 0.0055059 (117)\ttotal: 17m 27s\tremaining: 55m 52s\n",
      "119:\tlearn: 0.0043706\ttest: 0.0054875\tbest: 0.0054875 (119)\ttotal: 17m 35s\tremaining: 55m 43s\n",
      "120:\tlearn: 0.0043463\ttest: 0.0054580\tbest: 0.0054580 (120)\ttotal: 17m 44s\tremaining: 55m 34s\n",
      "121:\tlearn: 0.0043320\ttest: 0.0054470\tbest: 0.0054470 (121)\ttotal: 17m 53s\tremaining: 55m 25s\n",
      "122:\tlearn: 0.0043220\ttest: 0.0054212\tbest: 0.0054212 (122)\ttotal: 18m 2s\tremaining: 55m 16s\n",
      "123:\tlearn: 0.0042848\ttest: 0.0053955\tbest: 0.0053955 (123)\ttotal: 18m 10s\tremaining: 55m 8s\n",
      "124:\tlearn: 0.0042691\ttest: 0.0053955\tbest: 0.0053955 (123)\ttotal: 18m 19s\tremaining: 54m 59s\n",
      "125:\tlearn: 0.0042662\ttest: 0.0053844\tbest: 0.0053844 (125)\ttotal: 18m 28s\tremaining: 54m 51s\n",
      "126:\tlearn: 0.0042491\ttest: 0.0053771\tbest: 0.0053771 (126)\ttotal: 18m 37s\tremaining: 54m 42s\n",
      "127:\tlearn: 0.0042405\ttest: 0.0053623\tbest: 0.0053623 (127)\ttotal: 18m 46s\tremaining: 54m 33s\n",
      "128:\tlearn: 0.0042248\ttest: 0.0053513\tbest: 0.0053513 (128)\ttotal: 18m 55s\tremaining: 54m 25s\n",
      "129:\tlearn: 0.0042076\ttest: 0.0053550\tbest: 0.0053513 (128)\ttotal: 19m 4s\tremaining: 54m 16s\n",
      "130:\tlearn: 0.0041904\ttest: 0.0053439\tbest: 0.0053439 (130)\ttotal: 19m 12s\tremaining: 54m 7s\n",
      "131:\tlearn: 0.0041618\ttest: 0.0053182\tbest: 0.0053182 (131)\ttotal: 19m 21s\tremaining: 53m 58s\n",
      "132:\tlearn: 0.0041475\ttest: 0.0053219\tbest: 0.0053182 (131)\ttotal: 19m 30s\tremaining: 53m 49s\n",
      "133:\tlearn: 0.0041247\ttest: 0.0052924\tbest: 0.0052924 (133)\ttotal: 19m 39s\tremaining: 53m 41s\n",
      "134:\tlearn: 0.0040817\ttest: 0.0052666\tbest: 0.0052666 (134)\ttotal: 19m 48s\tremaining: 53m 32s\n",
      "135:\tlearn: 0.0040732\ttest: 0.0052482\tbest: 0.0052482 (135)\ttotal: 19m 56s\tremaining: 53m 23s\n",
      "136:\tlearn: 0.0040460\ttest: 0.0052446\tbest: 0.0052446 (136)\ttotal: 20m 5s\tremaining: 53m 14s\n",
      "137:\tlearn: 0.0040102\ttest: 0.0052041\tbest: 0.0052041 (137)\ttotal: 20m 14s\tremaining: 53m 5s\n",
      "138:\tlearn: 0.0039831\ttest: 0.0051820\tbest: 0.0051820 (138)\ttotal: 20m 23s\tremaining: 52m 56s\n",
      "139:\tlearn: 0.0039716\ttest: 0.0051673\tbest: 0.0051673 (139)\ttotal: 20m 31s\tremaining: 52m 47s\n",
      "140:\tlearn: 0.0039588\ttest: 0.0051636\tbest: 0.0051636 (140)\ttotal: 20m 40s\tremaining: 52m 38s\n",
      "141:\tlearn: 0.0039459\ttest: 0.0051599\tbest: 0.0051599 (141)\ttotal: 20m 49s\tremaining: 52m 30s\n",
      "142:\tlearn: 0.0039316\ttest: 0.0051489\tbest: 0.0051489 (142)\ttotal: 20m 58s\tremaining: 52m 21s\n",
      "143:\tlearn: 0.0039216\ttest: 0.0051489\tbest: 0.0051489 (142)\ttotal: 21m 6s\tremaining: 52m 12s\n",
      "144:\tlearn: 0.0039030\ttest: 0.0051231\tbest: 0.0051231 (144)\ttotal: 21m 15s\tremaining: 52m 3s\n",
      "145:\tlearn: 0.0038987\ttest: 0.0051157\tbest: 0.0051157 (145)\ttotal: 21m 24s\tremaining: 51m 54s\n",
      "146:\tlearn: 0.0038858\ttest: 0.0050973\tbest: 0.0050973 (146)\ttotal: 21m 33s\tremaining: 51m 45s\n",
      "147:\tlearn: 0.0038501\ttest: 0.0050679\tbest: 0.0050679 (147)\ttotal: 21m 42s\tremaining: 51m 36s\n",
      "148:\tlearn: 0.0038429\ttest: 0.0050495\tbest: 0.0050495 (148)\ttotal: 21m 50s\tremaining: 51m 27s\n",
      "149:\tlearn: 0.0038043\ttest: 0.0050495\tbest: 0.0050495 (148)\ttotal: 21m 59s\tremaining: 51m 19s\n",
      "150:\tlearn: 0.0037843\ttest: 0.0050421\tbest: 0.0050421 (150)\ttotal: 22m 8s\tremaining: 51m 10s\n",
      "151:\tlearn: 0.0037657\ttest: 0.0050090\tbest: 0.0050090 (151)\ttotal: 22m 17s\tremaining: 51m 1s\n",
      "152:\tlearn: 0.0037428\ttest: 0.0050090\tbest: 0.0050090 (151)\ttotal: 22m 26s\tremaining: 50m 52s\n",
      "153:\tlearn: 0.0037099\ttest: 0.0049980\tbest: 0.0049980 (153)\ttotal: 22m 34s\tremaining: 50m 44s\n",
      "154:\tlearn: 0.0036927\ttest: 0.0049906\tbest: 0.0049906 (154)\ttotal: 22m 43s\tremaining: 50m 35s\n",
      "155:\tlearn: 0.0036670\ttest: 0.0049833\tbest: 0.0049833 (155)\ttotal: 22m 52s\tremaining: 50m 26s\n",
      "156:\tlearn: 0.0036398\ttest: 0.0049685\tbest: 0.0049685 (156)\ttotal: 23m 1s\tremaining: 50m 18s\n",
      "157:\tlearn: 0.0036241\ttest: 0.0049501\tbest: 0.0049501 (157)\ttotal: 23m 10s\tremaining: 50m 9s\n",
      "158:\tlearn: 0.0035869\ttest: 0.0049280\tbest: 0.0049280 (158)\ttotal: 23m 19s\tremaining: 50m\n",
      "159:\tlearn: 0.0035769\ttest: 0.0049207\tbest: 0.0049207 (159)\ttotal: 23m 28s\tremaining: 49m 52s\n",
      "160:\tlearn: 0.0035683\ttest: 0.0049133\tbest: 0.0049133 (160)\ttotal: 23m 36s\tremaining: 49m 43s\n",
      "161:\tlearn: 0.0035469\ttest: 0.0049244\tbest: 0.0049133 (160)\ttotal: 23m 45s\tremaining: 49m 34s\n",
      "162:\tlearn: 0.0034997\ttest: 0.0048949\tbest: 0.0048949 (162)\ttotal: 23m 54s\tremaining: 49m 25s\n",
      "163:\tlearn: 0.0034925\ttest: 0.0048986\tbest: 0.0048949 (162)\ttotal: 24m 3s\tremaining: 49m 16s\n",
      "164:\tlearn: 0.0034711\ttest: 0.0048876\tbest: 0.0048876 (164)\ttotal: 24m 11s\tremaining: 49m 7s\n",
      "165:\tlearn: 0.0034653\ttest: 0.0048802\tbest: 0.0048802 (165)\ttotal: 24m 20s\tremaining: 48m 59s\n",
      "166:\tlearn: 0.0034467\ttest: 0.0048839\tbest: 0.0048802 (165)\ttotal: 24m 29s\tremaining: 48m 50s\n",
      "167:\tlearn: 0.0034210\ttest: 0.0048618\tbest: 0.0048618 (167)\ttotal: 24m 38s\tremaining: 48m 41s\n",
      "168:\tlearn: 0.0034096\ttest: 0.0048434\tbest: 0.0048434 (168)\ttotal: 24m 47s\tremaining: 48m 32s\n",
      "169:\tlearn: 0.0033924\ttest: 0.0048029\tbest: 0.0048029 (169)\ttotal: 24m 55s\tremaining: 48m 23s\n",
      "170:\tlearn: 0.0033767\ttest: 0.0047919\tbest: 0.0047919 (170)\ttotal: 25m 4s\tremaining: 48m 15s\n",
      "171:\tlearn: 0.0033509\ttest: 0.0047772\tbest: 0.0047772 (171)\ttotal: 25m 13s\tremaining: 48m 6s\n",
      "172:\tlearn: 0.0033094\ttest: 0.0047735\tbest: 0.0047735 (172)\ttotal: 25m 22s\tremaining: 47m 57s\n",
      "173:\tlearn: 0.0032909\ttest: 0.0047661\tbest: 0.0047661 (173)\ttotal: 25m 31s\tremaining: 47m 48s\n",
      "174:\tlearn: 0.0032680\ttest: 0.0047514\tbest: 0.0047514 (174)\ttotal: 25m 39s\tremaining: 47m 39s\n",
      "175:\tlearn: 0.0032608\ttest: 0.0047514\tbest: 0.0047514 (174)\ttotal: 25m 48s\tremaining: 47m 30s\n",
      "176:\tlearn: 0.0032580\ttest: 0.0047367\tbest: 0.0047367 (176)\ttotal: 25m 57s\tremaining: 47m 22s\n",
      "177:\tlearn: 0.0032408\ttest: 0.0047477\tbest: 0.0047367 (176)\ttotal: 26m 6s\tremaining: 47m 13s\n",
      "178:\tlearn: 0.0032108\ttest: 0.0047330\tbest: 0.0047330 (178)\ttotal: 26m 14s\tremaining: 47m 4s\n",
      "179:\tlearn: 0.0032036\ttest: 0.0047256\tbest: 0.0047256 (179)\ttotal: 26m 23s\tremaining: 46m 55s\n",
      "180:\tlearn: 0.0031993\ttest: 0.0047183\tbest: 0.0047183 (180)\ttotal: 26m 32s\tremaining: 46m 46s\n",
      "181:\tlearn: 0.0031779\ttest: 0.0046999\tbest: 0.0046999 (181)\ttotal: 26m 41s\tremaining: 46m 38s\n",
      "182:\tlearn: 0.0031650\ttest: 0.0047035\tbest: 0.0046999 (181)\ttotal: 26m 50s\tremaining: 46m 29s\n",
      "183:\tlearn: 0.0031507\ttest: 0.0047035\tbest: 0.0046999 (181)\ttotal: 26m 58s\tremaining: 46m 20s\n",
      "184:\tlearn: 0.0031393\ttest: 0.0046962\tbest: 0.0046962 (184)\ttotal: 27m 7s\tremaining: 46m 11s\n",
      "185:\tlearn: 0.0031207\ttest: 0.0047072\tbest: 0.0046962 (184)\ttotal: 27m 16s\tremaining: 46m 2s\n",
      "186:\tlearn: 0.0031049\ttest: 0.0046962\tbest: 0.0046962 (184)\ttotal: 27m 25s\tremaining: 45m 54s\n",
      "187:\tlearn: 0.0030892\ttest: 0.0046962\tbest: 0.0046962 (184)\ttotal: 27m 34s\tremaining: 45m 45s\n",
      "188:\tlearn: 0.0030806\ttest: 0.0046888\tbest: 0.0046888 (188)\ttotal: 27m 42s\tremaining: 45m 36s\n",
      "189:\tlearn: 0.0030677\ttest: 0.0046925\tbest: 0.0046888 (188)\ttotal: 27m 51s\tremaining: 45m 27s\n",
      "190:\tlearn: 0.0030449\ttest: 0.0046888\tbest: 0.0046888 (188)\ttotal: 28m\tremaining: 45m 18s\n",
      "191:\tlearn: 0.0030434\ttest: 0.0046815\tbest: 0.0046815 (191)\ttotal: 28m 9s\tremaining: 45m 10s\n",
      "192:\tlearn: 0.0030277\ttest: 0.0046373\tbest: 0.0046373 (192)\ttotal: 28m 18s\tremaining: 45m 1s\n",
      "193:\tlearn: 0.0030148\ttest: 0.0046152\tbest: 0.0046152 (193)\ttotal: 28m 26s\tremaining: 44m 52s\n",
      "194:\tlearn: 0.0030120\ttest: 0.0046079\tbest: 0.0046079 (194)\ttotal: 28m 35s\tremaining: 44m 43s\n",
      "195:\tlearn: 0.0029962\ttest: 0.0045968\tbest: 0.0045968 (195)\ttotal: 28m 44s\tremaining: 44m 34s\n",
      "196:\tlearn: 0.0029948\ttest: 0.0046005\tbest: 0.0045968 (195)\ttotal: 28m 53s\tremaining: 44m 25s\n",
      "197:\tlearn: 0.0029948\ttest: 0.0046005\tbest: 0.0045968 (195)\ttotal: 29m 2s\tremaining: 44m 17s\n",
      "198:\tlearn: 0.0029748\ttest: 0.0046042\tbest: 0.0045968 (195)\ttotal: 29m 10s\tremaining: 44m 8s\n",
      "199:\tlearn: 0.0029490\ttest: 0.0046005\tbest: 0.0045968 (195)\ttotal: 29m 19s\tremaining: 43m 59s\n",
      "200:\tlearn: 0.0029376\ttest: 0.0045895\tbest: 0.0045895 (200)\ttotal: 29m 28s\tremaining: 43m 50s\n",
      "201:\tlearn: 0.0029262\ttest: 0.0045858\tbest: 0.0045858 (201)\ttotal: 29m 37s\tremaining: 43m 41s\n",
      "202:\tlearn: 0.0029076\ttest: 0.0045747\tbest: 0.0045747 (202)\ttotal: 29m 46s\tremaining: 43m 33s\n",
      "203:\tlearn: 0.0028904\ttest: 0.0045490\tbest: 0.0045490 (203)\ttotal: 29m 54s\tremaining: 43m 24s\n",
      "204:\tlearn: 0.0028833\ttest: 0.0045379\tbest: 0.0045379 (204)\ttotal: 30m 3s\tremaining: 43m 15s\n",
      "205:\tlearn: 0.0028732\ttest: 0.0045379\tbest: 0.0045379 (204)\ttotal: 30m 12s\tremaining: 43m 6s\n",
      "206:\tlearn: 0.0028761\ttest: 0.0045379\tbest: 0.0045379 (204)\ttotal: 30m 21s\tremaining: 42m 57s\n",
      "207:\tlearn: 0.0028461\ttest: 0.0045195\tbest: 0.0045195 (207)\ttotal: 30m 29s\tremaining: 42m 48s\n",
      "208:\tlearn: 0.0028346\ttest: 0.0045232\tbest: 0.0045195 (207)\ttotal: 30m 38s\tremaining: 42m 39s\n",
      "209:\tlearn: 0.0028232\ttest: 0.0045232\tbest: 0.0045195 (207)\ttotal: 30m 47s\tremaining: 42m 31s\n",
      "210:\tlearn: 0.0028017\ttest: 0.0044938\tbest: 0.0044938 (210)\ttotal: 30m 56s\tremaining: 42m 22s\n",
      "211:\tlearn: 0.0027960\ttest: 0.0044938\tbest: 0.0044938 (210)\ttotal: 31m 4s\tremaining: 42m 13s\n",
      "212:\tlearn: 0.0027860\ttest: 0.0044754\tbest: 0.0044754 (212)\ttotal: 31m 13s\tremaining: 42m 4s\n",
      "213:\tlearn: 0.0027903\ttest: 0.0044827\tbest: 0.0044754 (212)\ttotal: 31m 22s\tremaining: 41m 56s\n",
      "214:\tlearn: 0.0027903\ttest: 0.0044754\tbest: 0.0044754 (212)\ttotal: 31m 31s\tremaining: 41m 47s\n",
      "215:\tlearn: 0.0027760\ttest: 0.0044680\tbest: 0.0044680 (215)\ttotal: 31m 40s\tremaining: 41m 38s\n",
      "216:\tlearn: 0.0027746\ttest: 0.0044827\tbest: 0.0044680 (215)\ttotal: 31m 49s\tremaining: 41m 30s\n",
      "217:\tlearn: 0.0027603\ttest: 0.0044680\tbest: 0.0044680 (215)\ttotal: 31m 58s\tremaining: 41m 21s\n",
      "218:\tlearn: 0.0027588\ttest: 0.0044643\tbest: 0.0044643 (218)\ttotal: 32m 6s\tremaining: 41m 12s\n",
      "219:\tlearn: 0.0027460\ttest: 0.0044570\tbest: 0.0044570 (219)\ttotal: 32m 15s\tremaining: 41m 3s\n",
      "220:\tlearn: 0.0027374\ttest: 0.0044496\tbest: 0.0044496 (220)\ttotal: 32m 24s\tremaining: 40m 54s\n",
      "221:\tlearn: 0.0027288\ttest: 0.0044459\tbest: 0.0044459 (221)\ttotal: 32m 33s\tremaining: 40m 46s\n",
      "222:\tlearn: 0.0027202\ttest: 0.0044238\tbest: 0.0044238 (222)\ttotal: 32m 42s\tremaining: 40m 37s\n",
      "223:\tlearn: 0.0027188\ttest: 0.0044165\tbest: 0.0044165 (223)\ttotal: 32m 51s\tremaining: 40m 28s\n",
      "224:\tlearn: 0.0027174\ttest: 0.0044165\tbest: 0.0044165 (223)\ttotal: 32m 59s\tremaining: 40m 19s\n",
      "225:\tlearn: 0.0027059\ttest: 0.0044275\tbest: 0.0044165 (223)\ttotal: 33m 8s\tremaining: 40m 10s\n",
      "226:\tlearn: 0.0026887\ttest: 0.0044238\tbest: 0.0044165 (223)\ttotal: 33m 17s\tremaining: 40m 2s\n",
      "227:\tlearn: 0.0026916\ttest: 0.0044202\tbest: 0.0044165 (223)\ttotal: 33m 26s\tremaining: 39m 53s\n",
      "228:\tlearn: 0.0026902\ttest: 0.0044238\tbest: 0.0044165 (223)\ttotal: 33m 34s\tremaining: 39m 44s\n",
      "229:\tlearn: 0.0026702\ttest: 0.0044275\tbest: 0.0044165 (223)\ttotal: 33m 43s\tremaining: 39m 35s\n",
      "230:\tlearn: 0.0026616\ttest: 0.0044091\tbest: 0.0044091 (230)\ttotal: 33m 52s\tremaining: 39m 26s\n",
      "231:\tlearn: 0.0026516\ttest: 0.0044202\tbest: 0.0044091 (230)\ttotal: 34m 1s\tremaining: 39m 18s\n",
      "232:\tlearn: 0.0026430\ttest: 0.0044018\tbest: 0.0044018 (232)\ttotal: 34m 10s\tremaining: 39m 9s\n",
      "233:\tlearn: 0.0026430\ttest: 0.0044018\tbest: 0.0044018 (232)\ttotal: 34m 18s\tremaining: 39m\n",
      "234:\tlearn: 0.0026315\ttest: 0.0044091\tbest: 0.0044018 (232)\ttotal: 34m 27s\tremaining: 38m 51s\n",
      "235:\tlearn: 0.0026087\ttest: 0.0044018\tbest: 0.0044018 (232)\ttotal: 34m 36s\tremaining: 38m 42s\n",
      "236:\tlearn: 0.0025872\ttest: 0.0043944\tbest: 0.0043944 (236)\ttotal: 34m 45s\tremaining: 38m 34s\n",
      "237:\tlearn: 0.0025686\ttest: 0.0043870\tbest: 0.0043870 (237)\ttotal: 34m 54s\tremaining: 38m 25s\n",
      "238:\tlearn: 0.0025700\ttest: 0.0043797\tbest: 0.0043797 (238)\ttotal: 35m 2s\tremaining: 38m 16s\n",
      "239:\tlearn: 0.0025700\ttest: 0.0043833\tbest: 0.0043797 (238)\ttotal: 35m 11s\tremaining: 38m 7s\n",
      "240:\tlearn: 0.0025643\ttest: 0.0043833\tbest: 0.0043797 (238)\ttotal: 35m 20s\tremaining: 37m 58s\n",
      "241:\tlearn: 0.0025429\ttest: 0.0043649\tbest: 0.0043649 (241)\ttotal: 35m 29s\tremaining: 37m 50s\n",
      "242:\tlearn: 0.0025371\ttest: 0.0043613\tbest: 0.0043613 (242)\ttotal: 35m 38s\tremaining: 37m 41s\n",
      "243:\tlearn: 0.0025343\ttest: 0.0043613\tbest: 0.0043613 (242)\ttotal: 35m 46s\tremaining: 37m 32s\n",
      "244:\tlearn: 0.0025371\ttest: 0.0043539\tbest: 0.0043539 (244)\ttotal: 35m 55s\tremaining: 37m 23s\n",
      "245:\tlearn: 0.0025371\ttest: 0.0043539\tbest: 0.0043539 (244)\ttotal: 36m 4s\tremaining: 37m 14s\n",
      "246:\tlearn: 0.0025343\ttest: 0.0043649\tbest: 0.0043539 (244)\ttotal: 36m 13s\tremaining: 37m 5s\n",
      "247:\tlearn: 0.0025257\ttest: 0.0043576\tbest: 0.0043539 (244)\ttotal: 36m 21s\tremaining: 36m 57s\n",
      "248:\tlearn: 0.0025200\ttest: 0.0043539\tbest: 0.0043539 (244)\ttotal: 36m 30s\tremaining: 36m 48s\n",
      "249:\tlearn: 0.0025186\ttest: 0.0043539\tbest: 0.0043539 (244)\ttotal: 36m 39s\tremaining: 36m 39s\n",
      "250:\tlearn: 0.0025157\ttest: 0.0043502\tbest: 0.0043502 (250)\ttotal: 36m 48s\tremaining: 36m 30s\n",
      "251:\tlearn: 0.0025028\ttest: 0.0043465\tbest: 0.0043465 (251)\ttotal: 36m 57s\tremaining: 36m 21s\n",
      "252:\tlearn: 0.0024971\ttest: 0.0043465\tbest: 0.0043465 (251)\ttotal: 37m 5s\tremaining: 36m 13s\n",
      "253:\tlearn: 0.0024942\ttest: 0.0043392\tbest: 0.0043392 (253)\ttotal: 37m 14s\tremaining: 36m 4s\n",
      "254:\tlearn: 0.0024942\ttest: 0.0043392\tbest: 0.0043392 (253)\ttotal: 37m 23s\tremaining: 35m 55s\n",
      "255:\tlearn: 0.0024842\ttest: 0.0043355\tbest: 0.0043355 (255)\ttotal: 37m 32s\tremaining: 35m 46s\n",
      "256:\tlearn: 0.0024871\ttest: 0.0043355\tbest: 0.0043355 (255)\ttotal: 37m 41s\tremaining: 35m 37s\n",
      "257:\tlearn: 0.0024842\ttest: 0.0043171\tbest: 0.0043171 (257)\ttotal: 37m 49s\tremaining: 35m 28s\n",
      "258:\tlearn: 0.0024842\ttest: 0.0043171\tbest: 0.0043171 (257)\ttotal: 37m 58s\tremaining: 35m 20s\n",
      "259:\tlearn: 0.0024842\ttest: 0.0043097\tbest: 0.0043097 (259)\ttotal: 38m 7s\tremaining: 35m 11s\n",
      "260:\tlearn: 0.0024685\ttest: 0.0043134\tbest: 0.0043097 (259)\ttotal: 38m 15s\tremaining: 35m 2s\n",
      "261:\tlearn: 0.0024542\ttest: 0.0043134\tbest: 0.0043097 (259)\ttotal: 38m 24s\tremaining: 34m 53s\n",
      "262:\tlearn: 0.0024370\ttest: 0.0043024\tbest: 0.0043024 (262)\ttotal: 38m 33s\tremaining: 34m 44s\n",
      "263:\tlearn: 0.0024242\ttest: 0.0043024\tbest: 0.0043024 (262)\ttotal: 38m 42s\tremaining: 34m 36s\n",
      "264:\tlearn: 0.0024213\ttest: 0.0043061\tbest: 0.0043024 (262)\ttotal: 38m 51s\tremaining: 34m 27s\n",
      "265:\tlearn: 0.0024170\ttest: 0.0043024\tbest: 0.0043024 (262)\ttotal: 38m 59s\tremaining: 34m 18s\n",
      "266:\tlearn: 0.0024084\ttest: 0.0042987\tbest: 0.0042987 (266)\ttotal: 39m 8s\tremaining: 34m 9s\n",
      "267:\tlearn: 0.0023984\ttest: 0.0042877\tbest: 0.0042877 (267)\ttotal: 39m 17s\tremaining: 34m\n",
      "268:\tlearn: 0.0023970\ttest: 0.0042877\tbest: 0.0042877 (267)\ttotal: 39m 26s\tremaining: 33m 51s\n",
      "269:\tlearn: 0.0023784\ttest: 0.0042840\tbest: 0.0042840 (269)\ttotal: 39m 34s\tremaining: 33m 43s\n",
      "270:\tlearn: 0.0023655\ttest: 0.0042913\tbest: 0.0042840 (269)\ttotal: 39m 43s\tremaining: 33m 34s\n",
      "271:\tlearn: 0.0023670\ttest: 0.0042877\tbest: 0.0042840 (269)\ttotal: 39m 52s\tremaining: 33m 25s\n",
      "272:\tlearn: 0.0023612\ttest: 0.0042877\tbest: 0.0042840 (269)\ttotal: 40m 1s\tremaining: 33m 16s\n",
      "273:\tlearn: 0.0023512\ttest: 0.0042913\tbest: 0.0042840 (269)\ttotal: 40m 10s\tremaining: 33m 8s\n",
      "274:\tlearn: 0.0023369\ttest: 0.0042840\tbest: 0.0042840 (269)\ttotal: 40m 19s\tremaining: 32m 59s\n",
      "275:\tlearn: 0.0023312\ttest: 0.0042877\tbest: 0.0042840 (269)\ttotal: 40m 27s\tremaining: 32m 50s\n",
      "276:\tlearn: 0.0023226\ttest: 0.0042950\tbest: 0.0042840 (269)\ttotal: 40m 36s\tremaining: 32m 41s\n",
      "277:\tlearn: 0.0023126\ttest: 0.0042840\tbest: 0.0042840 (269)\ttotal: 40m 45s\tremaining: 32m 32s\n",
      "278:\tlearn: 0.0023097\ttest: 0.0042803\tbest: 0.0042803 (278)\ttotal: 40m 54s\tremaining: 32m 24s\n",
      "279:\tlearn: 0.0023083\ttest: 0.0042803\tbest: 0.0042803 (278)\ttotal: 41m 3s\tremaining: 32m 15s\n",
      "280:\tlearn: 0.0023055\ttest: 0.0042803\tbest: 0.0042803 (278)\ttotal: 41m 11s\tremaining: 32m 6s\n",
      "281:\tlearn: 0.0022983\ttest: 0.0042619\tbest: 0.0042619 (281)\ttotal: 41m 20s\tremaining: 31m 57s\n",
      "282:\tlearn: 0.0022983\ttest: 0.0042582\tbest: 0.0042582 (282)\ttotal: 41m 29s\tremaining: 31m 48s\n",
      "283:\tlearn: 0.0022783\ttest: 0.0042435\tbest: 0.0042435 (283)\ttotal: 41m 38s\tremaining: 31m 40s\n",
      "284:\tlearn: 0.0022668\ttest: 0.0042472\tbest: 0.0042435 (283)\ttotal: 41m 46s\tremaining: 31m 31s\n",
      "285:\tlearn: 0.0022654\ttest: 0.0042472\tbest: 0.0042435 (283)\ttotal: 41m 55s\tremaining: 31m 22s\n",
      "286:\tlearn: 0.0022611\ttest: 0.0042435\tbest: 0.0042435 (283)\ttotal: 42m 4s\tremaining: 31m 13s\n",
      "287:\tlearn: 0.0022411\ttest: 0.0042509\tbest: 0.0042435 (283)\ttotal: 42m 13s\tremaining: 31m 4s\n",
      "288:\tlearn: 0.0022311\ttest: 0.0042398\tbest: 0.0042398 (288)\ttotal: 42m 22s\tremaining: 30m 56s\n",
      "289:\tlearn: 0.0022339\ttest: 0.0042398\tbest: 0.0042398 (288)\ttotal: 42m 31s\tremaining: 30m 47s\n",
      "290:\tlearn: 0.0022154\ttest: 0.0042251\tbest: 0.0042251 (290)\ttotal: 42m 39s\tremaining: 30m 38s\n",
      "291:\tlearn: 0.0022139\ttest: 0.0042251\tbest: 0.0042251 (290)\ttotal: 42m 48s\tremaining: 30m 29s\n",
      "292:\tlearn: 0.0022111\ttest: 0.0042251\tbest: 0.0042251 (290)\ttotal: 42m 57s\tremaining: 30m 20s\n",
      "293:\tlearn: 0.0021996\ttest: 0.0042214\tbest: 0.0042214 (293)\ttotal: 43m 6s\tremaining: 30m 12s\n",
      "294:\tlearn: 0.0021925\ttest: 0.0042214\tbest: 0.0042214 (293)\ttotal: 43m 14s\tremaining: 30m 3s\n",
      "295:\tlearn: 0.0021810\ttest: 0.0042214\tbest: 0.0042214 (293)\ttotal: 43m 23s\tremaining: 29m 54s\n",
      "296:\tlearn: 0.0021782\ttest: 0.0042141\tbest: 0.0042141 (296)\ttotal: 43m 32s\tremaining: 29m 45s\n",
      "297:\tlearn: 0.0021767\ttest: 0.0042141\tbest: 0.0042141 (296)\ttotal: 43m 41s\tremaining: 29m 36s\n",
      "298:\tlearn: 0.0021739\ttest: 0.0042141\tbest: 0.0042141 (296)\ttotal: 43m 50s\tremaining: 29m 28s\n",
      "299:\tlearn: 0.0021739\ttest: 0.0042141\tbest: 0.0042141 (296)\ttotal: 43m 58s\tremaining: 29m 19s\n",
      "300:\tlearn: 0.0021667\ttest: 0.0042104\tbest: 0.0042104 (300)\ttotal: 44m 7s\tremaining: 29m 10s\n",
      "301:\tlearn: 0.0021567\ttest: 0.0041993\tbest: 0.0041993 (301)\ttotal: 44m 16s\tremaining: 29m 1s\n",
      "302:\tlearn: 0.0021424\ttest: 0.0041956\tbest: 0.0041956 (302)\ttotal: 44m 25s\tremaining: 28m 52s\n",
      "303:\tlearn: 0.0021338\ttest: 0.0041920\tbest: 0.0041920 (303)\ttotal: 44m 33s\tremaining: 28m 43s\n",
      "304:\tlearn: 0.0021338\ttest: 0.0041883\tbest: 0.0041883 (304)\ttotal: 44m 42s\tremaining: 28m 35s\n",
      "305:\tlearn: 0.0021324\ttest: 0.0041883\tbest: 0.0041883 (304)\ttotal: 44m 51s\tremaining: 28m 26s\n",
      "306:\tlearn: 0.0021281\ttest: 0.0041846\tbest: 0.0041846 (306)\ttotal: 45m\tremaining: 28m 17s\n",
      "307:\tlearn: 0.0021224\ttest: 0.0041809\tbest: 0.0041809 (307)\ttotal: 45m 9s\tremaining: 28m 8s\n",
      "308:\tlearn: 0.0021224\ttest: 0.0041809\tbest: 0.0041809 (307)\ttotal: 45m 17s\tremaining: 27m 59s\n",
      "309:\tlearn: 0.0021210\ttest: 0.0041846\tbest: 0.0041809 (307)\ttotal: 45m 26s\tremaining: 27m 51s\n",
      "310:\tlearn: 0.0021195\ttest: 0.0041846\tbest: 0.0041809 (307)\ttotal: 45m 35s\tremaining: 27m 42s\n",
      "311:\tlearn: 0.0021095\ttest: 0.0041772\tbest: 0.0041772 (311)\ttotal: 45m 44s\tremaining: 27m 33s\n",
      "312:\tlearn: 0.0020909\ttest: 0.0041662\tbest: 0.0041662 (312)\ttotal: 45m 52s\tremaining: 27m 24s\n",
      "313:\tlearn: 0.0020824\ttest: 0.0041625\tbest: 0.0041625 (313)\ttotal: 46m 1s\tremaining: 27m 15s\n",
      "314:\tlearn: 0.0020723\ttest: 0.0041736\tbest: 0.0041625 (313)\ttotal: 46m 10s\tremaining: 27m 7s\n",
      "315:\tlearn: 0.0020580\ttest: 0.0041625\tbest: 0.0041625 (313)\ttotal: 46m 19s\tremaining: 26m 58s\n",
      "316:\tlearn: 0.0020552\ttest: 0.0041625\tbest: 0.0041625 (313)\ttotal: 46m 27s\tremaining: 26m 49s\n",
      "317:\tlearn: 0.0020566\ttest: 0.0041625\tbest: 0.0041625 (313)\ttotal: 46m 36s\tremaining: 26m 40s\n",
      "318:\tlearn: 0.0020394\ttest: 0.0041588\tbest: 0.0041588 (318)\ttotal: 46m 45s\tremaining: 26m 31s\n",
      "319:\tlearn: 0.0020309\ttest: 0.0041699\tbest: 0.0041588 (318)\ttotal: 46m 54s\tremaining: 26m 22s\n",
      "320:\tlearn: 0.0020294\ttest: 0.0041699\tbest: 0.0041588 (318)\ttotal: 47m 2s\tremaining: 26m 14s\n",
      "321:\tlearn: 0.0020323\ttest: 0.0041662\tbest: 0.0041588 (318)\ttotal: 47m 11s\tremaining: 26m 5s\n",
      "322:\tlearn: 0.0020323\ttest: 0.0041588\tbest: 0.0041588 (318)\ttotal: 47m 20s\tremaining: 25m 56s\n",
      "323:\tlearn: 0.0020323\ttest: 0.0041552\tbest: 0.0041552 (323)\ttotal: 47m 29s\tremaining: 25m 47s\n",
      "324:\tlearn: 0.0020309\ttest: 0.0041552\tbest: 0.0041552 (323)\ttotal: 47m 38s\tremaining: 25m 38s\n",
      "325:\tlearn: 0.0020151\ttest: 0.0041552\tbest: 0.0041552 (323)\ttotal: 47m 46s\tremaining: 25m 30s\n",
      "326:\tlearn: 0.0020066\ttest: 0.0041515\tbest: 0.0041515 (326)\ttotal: 47m 55s\tremaining: 25m 21s\n",
      "327:\tlearn: 0.0020080\ttest: 0.0041515\tbest: 0.0041515 (326)\ttotal: 48m 4s\tremaining: 25m 12s\n",
      "328:\tlearn: 0.0020066\ttest: 0.0041478\tbest: 0.0041478 (328)\ttotal: 48m 13s\tremaining: 25m 3s\n",
      "329:\tlearn: 0.0020066\ttest: 0.0041478\tbest: 0.0041478 (328)\ttotal: 48m 21s\tremaining: 24m 54s\n",
      "330:\tlearn: 0.0019980\ttest: 0.0041441\tbest: 0.0041441 (330)\ttotal: 48m 30s\tremaining: 24m 46s\n",
      "331:\tlearn: 0.0019965\ttest: 0.0041404\tbest: 0.0041404 (331)\ttotal: 48m 39s\tremaining: 24m 37s\n",
      "332:\tlearn: 0.0019965\ttest: 0.0041404\tbest: 0.0041404 (331)\ttotal: 48m 48s\tremaining: 24m 28s\n",
      "333:\tlearn: 0.0019837\ttest: 0.0041441\tbest: 0.0041404 (331)\ttotal: 48m 57s\tremaining: 24m 19s\n",
      "334:\tlearn: 0.0019779\ttest: 0.0041441\tbest: 0.0041404 (331)\ttotal: 49m 5s\tremaining: 24m 10s\n",
      "335:\tlearn: 0.0019808\ttest: 0.0041257\tbest: 0.0041257 (335)\ttotal: 49m 14s\tremaining: 24m 2s\n",
      "336:\tlearn: 0.0019765\ttest: 0.0041220\tbest: 0.0041220 (336)\ttotal: 49m 23s\tremaining: 23m 53s\n",
      "337:\tlearn: 0.0019737\ttest: 0.0041220\tbest: 0.0041220 (336)\ttotal: 49m 32s\tremaining: 23m 44s\n",
      "338:\tlearn: 0.0019679\ttest: 0.0041147\tbest: 0.0041147 (338)\ttotal: 49m 40s\tremaining: 23m 35s\n",
      "339:\tlearn: 0.0019651\ttest: 0.0041110\tbest: 0.0041110 (339)\ttotal: 49m 49s\tremaining: 23m 26s\n",
      "340:\tlearn: 0.0019636\ttest: 0.0041110\tbest: 0.0041110 (339)\ttotal: 49m 58s\tremaining: 23m 18s\n",
      "341:\tlearn: 0.0019622\ttest: 0.0041110\tbest: 0.0041110 (339)\ttotal: 50m 7s\tremaining: 23m 9s\n",
      "342:\tlearn: 0.0019451\ttest: 0.0041110\tbest: 0.0041110 (339)\ttotal: 50m 16s\tremaining: 23m\n",
      "343:\tlearn: 0.0019451\ttest: 0.0041036\tbest: 0.0041036 (343)\ttotal: 50m 24s\tremaining: 22m 51s\n",
      "344:\tlearn: 0.0019451\ttest: 0.0041110\tbest: 0.0041036 (343)\ttotal: 50m 33s\tremaining: 22m 42s\n",
      "345:\tlearn: 0.0019451\ttest: 0.0041110\tbest: 0.0041036 (343)\ttotal: 50m 42s\tremaining: 22m 34s\n",
      "346:\tlearn: 0.0019322\ttest: 0.0041073\tbest: 0.0041036 (343)\ttotal: 50m 51s\tremaining: 22m 25s\n",
      "347:\tlearn: 0.0019236\ttest: 0.0040852\tbest: 0.0040852 (347)\ttotal: 51m\tremaining: 22m 16s\n",
      "348:\tlearn: 0.0019207\ttest: 0.0040742\tbest: 0.0040742 (348)\ttotal: 51m 8s\tremaining: 22m 7s\n",
      "349:\tlearn: 0.0019050\ttest: 0.0040742\tbest: 0.0040742 (348)\ttotal: 51m 17s\tremaining: 21m 59s\n",
      "350:\tlearn: 0.0019036\ttest: 0.0040632\tbest: 0.0040632 (350)\ttotal: 51m 26s\tremaining: 21m 50s\n",
      "351:\tlearn: 0.0018993\ttest: 0.0040521\tbest: 0.0040521 (351)\ttotal: 51m 35s\tremaining: 21m 41s\n",
      "352:\tlearn: 0.0018993\ttest: 0.0040521\tbest: 0.0040521 (351)\ttotal: 51m 44s\tremaining: 21m 32s\n",
      "353:\tlearn: 0.0018993\ttest: 0.0040521\tbest: 0.0040521 (351)\ttotal: 51m 52s\tremaining: 21m 23s\n",
      "354:\tlearn: 0.0018878\ttest: 0.0040448\tbest: 0.0040448 (354)\ttotal: 52m 1s\tremaining: 21m 15s\n",
      "355:\tlearn: 0.0018878\ttest: 0.0040411\tbest: 0.0040411 (355)\ttotal: 52m 10s\tremaining: 21m 6s\n",
      "356:\tlearn: 0.0018850\ttest: 0.0040411\tbest: 0.0040411 (355)\ttotal: 52m 19s\tremaining: 20m 57s\n",
      "357:\tlearn: 0.0018750\ttest: 0.0040374\tbest: 0.0040374 (357)\ttotal: 52m 28s\tremaining: 20m 48s\n",
      "358:\tlearn: 0.0018764\ttest: 0.0040411\tbest: 0.0040374 (357)\ttotal: 52m 36s\tremaining: 20m 39s\n",
      "359:\tlearn: 0.0018707\ttest: 0.0040411\tbest: 0.0040374 (357)\ttotal: 52m 45s\tremaining: 20m 31s\n",
      "360:\tlearn: 0.0018735\ttest: 0.0040411\tbest: 0.0040374 (357)\ttotal: 52m 54s\tremaining: 20m 22s\n",
      "361:\tlearn: 0.0018550\ttest: 0.0040558\tbest: 0.0040374 (357)\ttotal: 53m 3s\tremaining: 20m 13s\n",
      "362:\tlearn: 0.0018507\ttest: 0.0040411\tbest: 0.0040374 (357)\ttotal: 53m 12s\tremaining: 20m 4s\n",
      "363:\tlearn: 0.0018492\ttest: 0.0040411\tbest: 0.0040374 (357)\ttotal: 53m 20s\tremaining: 19m 55s\n",
      "364:\tlearn: 0.0018435\ttest: 0.0040484\tbest: 0.0040374 (357)\ttotal: 53m 29s\tremaining: 19m 47s\n",
      "365:\tlearn: 0.0018392\ttest: 0.0040484\tbest: 0.0040374 (357)\ttotal: 53m 38s\tremaining: 19m 38s\n",
      "366:\tlearn: 0.0018392\ttest: 0.0040484\tbest: 0.0040374 (357)\ttotal: 53m 47s\tremaining: 19m 29s\n",
      "367:\tlearn: 0.0018406\ttest: 0.0040484\tbest: 0.0040374 (357)\ttotal: 53m 55s\tremaining: 19m 20s\n",
      "368:\tlearn: 0.0018392\ttest: 0.0040484\tbest: 0.0040374 (357)\ttotal: 54m 4s\tremaining: 19m 11s\n",
      "369:\tlearn: 0.0018321\ttest: 0.0040484\tbest: 0.0040374 (357)\ttotal: 54m 13s\tremaining: 19m 3s\n",
      "370:\tlearn: 0.0018278\ttest: 0.0040484\tbest: 0.0040374 (357)\ttotal: 54m 22s\tremaining: 18m 54s\n",
      "371:\tlearn: 0.0018206\ttest: 0.0040521\tbest: 0.0040374 (357)\ttotal: 54m 31s\tremaining: 18m 45s\n",
      "372:\tlearn: 0.0018106\ttest: 0.0040411\tbest: 0.0040374 (357)\ttotal: 54m 40s\tremaining: 18m 36s\n",
      "373:\tlearn: 0.0018020\ttest: 0.0040337\tbest: 0.0040337 (373)\ttotal: 54m 48s\tremaining: 18m 28s\n",
      "374:\tlearn: 0.0018006\ttest: 0.0040374\tbest: 0.0040337 (373)\ttotal: 54m 57s\tremaining: 18m 19s\n",
      "375:\tlearn: 0.0017863\ttest: 0.0040374\tbest: 0.0040337 (373)\ttotal: 55m 6s\tremaining: 18m 10s\n",
      "376:\tlearn: 0.0017863\ttest: 0.0040300\tbest: 0.0040300 (376)\ttotal: 55m 15s\tremaining: 18m 1s\n",
      "377:\tlearn: 0.0017806\ttest: 0.0040300\tbest: 0.0040300 (376)\ttotal: 55m 23s\tremaining: 17m 52s\n",
      "378:\tlearn: 0.0017820\ttest: 0.0040300\tbest: 0.0040300 (376)\ttotal: 55m 32s\tremaining: 17m 44s\n",
      "379:\tlearn: 0.0017863\ttest: 0.0040264\tbest: 0.0040264 (379)\ttotal: 55m 41s\tremaining: 17m 35s\n",
      "380:\tlearn: 0.0017792\ttest: 0.0040264\tbest: 0.0040264 (379)\ttotal: 55m 50s\tremaining: 17m 26s\n",
      "381:\tlearn: 0.0017777\ttest: 0.0040448\tbest: 0.0040264 (379)\ttotal: 55m 59s\tremaining: 17m 17s\n",
      "382:\tlearn: 0.0017663\ttest: 0.0040411\tbest: 0.0040264 (379)\ttotal: 56m 7s\tremaining: 17m 8s\n",
      "383:\tlearn: 0.0017634\ttest: 0.0040411\tbest: 0.0040264 (379)\ttotal: 56m 16s\tremaining: 17m\n",
      "384:\tlearn: 0.0017620\ttest: 0.0040411\tbest: 0.0040264 (379)\ttotal: 56m 25s\tremaining: 16m 51s\n",
      "385:\tlearn: 0.0017534\ttest: 0.0040411\tbest: 0.0040264 (379)\ttotal: 56m 34s\tremaining: 16m 42s\n",
      "386:\tlearn: 0.0017548\ttest: 0.0040411\tbest: 0.0040264 (379)\ttotal: 56m 43s\tremaining: 16m 33s\n",
      "387:\tlearn: 0.0017434\ttest: 0.0040264\tbest: 0.0040264 (379)\ttotal: 56m 51s\tremaining: 16m 24s\n",
      "388:\tlearn: 0.0017362\ttest: 0.0040190\tbest: 0.0040190 (388)\ttotal: 57m\tremaining: 16m 16s\n",
      "389:\tlearn: 0.0017320\ttest: 0.0040079\tbest: 0.0040079 (389)\ttotal: 57m 9s\tremaining: 16m 7s\n",
      "390:\tlearn: 0.0017177\ttest: 0.0040153\tbest: 0.0040079 (389)\ttotal: 57m 18s\tremaining: 15m 58s\n",
      "391:\tlearn: 0.0017091\ttest: 0.0039969\tbest: 0.0039969 (391)\ttotal: 57m 26s\tremaining: 15m 49s\n",
      "392:\tlearn: 0.0017091\ttest: 0.0039932\tbest: 0.0039932 (392)\ttotal: 57m 35s\tremaining: 15m 40s\n",
      "393:\tlearn: 0.0017091\ttest: 0.0039932\tbest: 0.0039932 (392)\ttotal: 57m 44s\tremaining: 15m 32s\n",
      "394:\tlearn: 0.0017048\ttest: 0.0039748\tbest: 0.0039748 (394)\ttotal: 57m 53s\tremaining: 15m 23s\n",
      "395:\tlearn: 0.0016991\ttest: 0.0039785\tbest: 0.0039748 (394)\ttotal: 58m 1s\tremaining: 15m 14s\n",
      "396:\tlearn: 0.0016933\ttest: 0.0039785\tbest: 0.0039748 (394)\ttotal: 58m 10s\tremaining: 15m 5s\n",
      "397:\tlearn: 0.0016948\ttest: 0.0039785\tbest: 0.0039748 (394)\ttotal: 58m 19s\tremaining: 14m 56s\n",
      "398:\tlearn: 0.0016905\ttest: 0.0039638\tbest: 0.0039638 (398)\ttotal: 58m 28s\tremaining: 14m 48s\n",
      "399:\tlearn: 0.0016890\ttest: 0.0039675\tbest: 0.0039638 (398)\ttotal: 58m 37s\tremaining: 14m 39s\n",
      "400:\tlearn: 0.0016905\ttest: 0.0039675\tbest: 0.0039638 (398)\ttotal: 58m 45s\tremaining: 14m 30s\n",
      "401:\tlearn: 0.0016905\ttest: 0.0039675\tbest: 0.0039638 (398)\ttotal: 58m 54s\tremaining: 14m 21s\n",
      "402:\tlearn: 0.0016890\ttest: 0.0039675\tbest: 0.0039638 (398)\ttotal: 59m 3s\tremaining: 14m 12s\n",
      "403:\tlearn: 0.0016776\ttest: 0.0039748\tbest: 0.0039638 (398)\ttotal: 59m 12s\tremaining: 14m 4s\n",
      "404:\tlearn: 0.0016705\ttest: 0.0039675\tbest: 0.0039638 (398)\ttotal: 59m 21s\tremaining: 13m 55s\n",
      "405:\tlearn: 0.0016690\ttest: 0.0039675\tbest: 0.0039638 (398)\ttotal: 59m 29s\tremaining: 13m 46s\n",
      "406:\tlearn: 0.0016662\ttest: 0.0039711\tbest: 0.0039638 (398)\ttotal: 59m 38s\tremaining: 13m 37s\n",
      "407:\tlearn: 0.0016662\ttest: 0.0039711\tbest: 0.0039638 (398)\ttotal: 59m 47s\tremaining: 13m 28s\n",
      "408:\tlearn: 0.0016705\ttest: 0.0039675\tbest: 0.0039638 (398)\ttotal: 59m 56s\tremaining: 13m 20s\n",
      "409:\tlearn: 0.0016676\ttest: 0.0039601\tbest: 0.0039601 (409)\ttotal: 1h 5s\tremaining: 13m 11s\n",
      "410:\tlearn: 0.0016619\ttest: 0.0039638\tbest: 0.0039601 (409)\ttotal: 1h 13s\tremaining: 13m 2s\n",
      "411:\tlearn: 0.0016533\ttest: 0.0039638\tbest: 0.0039601 (409)\ttotal: 1h 22s\tremaining: 12m 53s\n",
      "412:\tlearn: 0.0016533\ttest: 0.0039638\tbest: 0.0039601 (409)\ttotal: 1h 31s\tremaining: 12m 45s\n",
      "413:\tlearn: 0.0016547\ttest: 0.0039601\tbest: 0.0039601 (409)\ttotal: 1h 40s\tremaining: 12m 36s\n",
      "414:\tlearn: 0.0016533\ttest: 0.0039601\tbest: 0.0039601 (409)\ttotal: 1h 49s\tremaining: 12m 27s\n",
      "415:\tlearn: 0.0016419\ttest: 0.0039491\tbest: 0.0039491 (415)\ttotal: 1h 57s\tremaining: 12m 18s\n",
      "416:\tlearn: 0.0016390\ttest: 0.0039491\tbest: 0.0039491 (415)\ttotal: 1h 1m 6s\tremaining: 12m 9s\n",
      "417:\tlearn: 0.0016390\ttest: 0.0039491\tbest: 0.0039491 (415)\ttotal: 1h 1m 15s\tremaining: 12m 1s\n",
      "418:\tlearn: 0.0016376\ttest: 0.0039491\tbest: 0.0039491 (415)\ttotal: 1h 1m 24s\tremaining: 11m 52s\n",
      "419:\tlearn: 0.0016204\ttest: 0.0039491\tbest: 0.0039491 (415)\ttotal: 1h 1m 33s\tremaining: 11m 43s\n",
      "420:\tlearn: 0.0016118\ttest: 0.0039491\tbest: 0.0039491 (415)\ttotal: 1h 1m 41s\tremaining: 11m 34s\n",
      "421:\tlearn: 0.0016090\ttest: 0.0039491\tbest: 0.0039491 (415)\ttotal: 1h 1m 50s\tremaining: 11m 25s\n",
      "422:\tlearn: 0.0016075\ttest: 0.0039343\tbest: 0.0039343 (422)\ttotal: 1h 1m 59s\tremaining: 11m 17s\n",
      "423:\tlearn: 0.0016061\ttest: 0.0039343\tbest: 0.0039343 (422)\ttotal: 1h 2m 8s\tremaining: 11m 8s\n",
      "424:\tlearn: 0.0016032\ttest: 0.0039307\tbest: 0.0039307 (424)\ttotal: 1h 2m 17s\tremaining: 10m 59s\n",
      "425:\tlearn: 0.0016018\ttest: 0.0039307\tbest: 0.0039307 (424)\ttotal: 1h 2m 25s\tremaining: 10m 50s\n",
      "426:\tlearn: 0.0015989\ttest: 0.0039233\tbest: 0.0039233 (426)\ttotal: 1h 2m 34s\tremaining: 10m 41s\n",
      "427:\tlearn: 0.0015989\ttest: 0.0039233\tbest: 0.0039233 (426)\ttotal: 1h 2m 43s\tremaining: 10m 33s\n",
      "428:\tlearn: 0.0015918\ttest: 0.0039196\tbest: 0.0039196 (428)\ttotal: 1h 2m 52s\tremaining: 10m 24s\n",
      "429:\tlearn: 0.0015918\ttest: 0.0039196\tbest: 0.0039196 (428)\ttotal: 1h 3m 1s\tremaining: 10m 15s\n",
      "430:\tlearn: 0.0015918\ttest: 0.0039196\tbest: 0.0039196 (428)\ttotal: 1h 3m 9s\tremaining: 10m 6s\n",
      "431:\tlearn: 0.0015775\ttest: 0.0039196\tbest: 0.0039196 (428)\ttotal: 1h 3m 18s\tremaining: 9m 57s\n",
      "432:\tlearn: 0.0015789\ttest: 0.0039233\tbest: 0.0039196 (428)\ttotal: 1h 3m 27s\tremaining: 9m 49s\n",
      "433:\tlearn: 0.0015789\ttest: 0.0039233\tbest: 0.0039196 (428)\ttotal: 1h 3m 36s\tremaining: 9m 40s\n",
      "434:\tlearn: 0.0015761\ttest: 0.0039233\tbest: 0.0039196 (428)\ttotal: 1h 3m 45s\tremaining: 9m 31s\n",
      "435:\tlearn: 0.0015775\ttest: 0.0039233\tbest: 0.0039196 (428)\ttotal: 1h 3m 54s\tremaining: 9m 22s\n",
      "436:\tlearn: 0.0015804\ttest: 0.0039233\tbest: 0.0039196 (428)\ttotal: 1h 4m 2s\tremaining: 9m 14s\n",
      "437:\tlearn: 0.0015646\ttest: 0.0039196\tbest: 0.0039196 (428)\ttotal: 1h 4m 11s\tremaining: 9m 5s\n",
      "438:\tlearn: 0.0015632\ttest: 0.0039196\tbest: 0.0039196 (428)\ttotal: 1h 4m 20s\tremaining: 8m 56s\n",
      "439:\tlearn: 0.0015618\ttest: 0.0039196\tbest: 0.0039196 (428)\ttotal: 1h 4m 29s\tremaining: 8m 47s\n",
      "440:\tlearn: 0.0015618\ttest: 0.0039196\tbest: 0.0039196 (428)\ttotal: 1h 4m 38s\tremaining: 8m 38s\n",
      "441:\tlearn: 0.0015618\ttest: 0.0039196\tbest: 0.0039196 (428)\ttotal: 1h 4m 46s\tremaining: 8m 30s\n",
      "442:\tlearn: 0.0015618\ttest: 0.0039196\tbest: 0.0039196 (428)\ttotal: 1h 4m 55s\tremaining: 8m 21s\n",
      "443:\tlearn: 0.0015603\ttest: 0.0039233\tbest: 0.0039196 (428)\ttotal: 1h 5m 4s\tremaining: 8m 12s\n",
      "444:\tlearn: 0.0015546\ttest: 0.0039233\tbest: 0.0039196 (428)\ttotal: 1h 5m 13s\tremaining: 8m 3s\n",
      "445:\tlearn: 0.0015489\ttest: 0.0039233\tbest: 0.0039196 (428)\ttotal: 1h 5m 22s\tremaining: 7m 54s\n",
      "446:\tlearn: 0.0015475\ttest: 0.0039233\tbest: 0.0039196 (428)\ttotal: 1h 5m 30s\tremaining: 7m 46s\n",
      "447:\tlearn: 0.0015475\ttest: 0.0039196\tbest: 0.0039196 (428)\ttotal: 1h 5m 39s\tremaining: 7m 37s\n",
      "448:\tlearn: 0.0015446\ttest: 0.0039233\tbest: 0.0039196 (428)\ttotal: 1h 5m 48s\tremaining: 7m 28s\n",
      "449:\tlearn: 0.0015417\ttest: 0.0039270\tbest: 0.0039196 (428)\ttotal: 1h 5m 57s\tremaining: 7m 19s\n",
      "450:\tlearn: 0.0015346\ttest: 0.0039233\tbest: 0.0039196 (428)\ttotal: 1h 6m 6s\tremaining: 7m 10s\n",
      "451:\tlearn: 0.0015274\ttest: 0.0039233\tbest: 0.0039196 (428)\ttotal: 1h 6m 14s\tremaining: 7m 2s\n",
      "452:\tlearn: 0.0015274\ttest: 0.0039233\tbest: 0.0039196 (428)\ttotal: 1h 6m 23s\tremaining: 6m 53s\n",
      "453:\tlearn: 0.0015289\ttest: 0.0039233\tbest: 0.0039196 (428)\ttotal: 1h 6m 32s\tremaining: 6m 44s\n",
      "454:\tlearn: 0.0015260\ttest: 0.0039270\tbest: 0.0039196 (428)\ttotal: 1h 6m 41s\tremaining: 6m 35s\n",
      "455:\tlearn: 0.0015103\ttest: 0.0039196\tbest: 0.0039196 (428)\ttotal: 1h 6m 49s\tremaining: 6m 26s\n",
      "456:\tlearn: 0.0015031\ttest: 0.0039123\tbest: 0.0039123 (456)\ttotal: 1h 6m 58s\tremaining: 6m 18s\n",
      "457:\tlearn: 0.0015003\ttest: 0.0039123\tbest: 0.0039123 (456)\ttotal: 1h 7m 7s\tremaining: 6m 9s\n",
      "458:\tlearn: 0.0014988\ttest: 0.0039123\tbest: 0.0039123 (456)\ttotal: 1h 7m 16s\tremaining: 6m\n",
      "459:\tlearn: 0.0014945\ttest: 0.0039049\tbest: 0.0039049 (459)\ttotal: 1h 7m 25s\tremaining: 5m 51s\n",
      "460:\tlearn: 0.0014974\ttest: 0.0039049\tbest: 0.0039049 (459)\ttotal: 1h 7m 33s\tremaining: 5m 42s\n",
      "461:\tlearn: 0.0014960\ttest: 0.0039049\tbest: 0.0039049 (459)\ttotal: 1h 7m 42s\tremaining: 5m 34s\n",
      "462:\tlearn: 0.0014960\ttest: 0.0039086\tbest: 0.0039049 (459)\ttotal: 1h 7m 51s\tremaining: 5m 25s\n",
      "463:\tlearn: 0.0014960\ttest: 0.0039123\tbest: 0.0039049 (459)\ttotal: 1h 8m\tremaining: 5m 16s\n",
      "464:\tlearn: 0.0014903\ttest: 0.0039049\tbest: 0.0039049 (459)\ttotal: 1h 8m 9s\tremaining: 5m 7s\n",
      "465:\tlearn: 0.0014931\ttest: 0.0039049\tbest: 0.0039049 (459)\ttotal: 1h 8m 18s\tremaining: 4m 59s\n",
      "466:\tlearn: 0.0014903\ttest: 0.0038975\tbest: 0.0038975 (466)\ttotal: 1h 8m 26s\tremaining: 4m 50s\n",
      "467:\tlearn: 0.0014888\ttest: 0.0039012\tbest: 0.0038975 (466)\ttotal: 1h 8m 35s\tremaining: 4m 41s\n",
      "468:\tlearn: 0.0014845\ttest: 0.0039086\tbest: 0.0038975 (466)\ttotal: 1h 8m 44s\tremaining: 4m 32s\n",
      "469:\tlearn: 0.0014788\ttest: 0.0039049\tbest: 0.0038975 (466)\ttotal: 1h 8m 53s\tremaining: 4m 23s\n",
      "470:\tlearn: 0.0014774\ttest: 0.0039012\tbest: 0.0038975 (466)\ttotal: 1h 9m 1s\tremaining: 4m 15s\n",
      "471:\tlearn: 0.0014745\ttest: 0.0038975\tbest: 0.0038975 (466)\ttotal: 1h 9m 10s\tremaining: 4m 6s\n",
      "472:\tlearn: 0.0014731\ttest: 0.0039012\tbest: 0.0038975 (466)\ttotal: 1h 9m 19s\tremaining: 3m 57s\n",
      "473:\tlearn: 0.0014760\ttest: 0.0038975\tbest: 0.0038975 (466)\ttotal: 1h 9m 28s\tremaining: 3m 48s\n",
      "474:\tlearn: 0.0014760\ttest: 0.0038975\tbest: 0.0038975 (466)\ttotal: 1h 9m 37s\tremaining: 3m 39s\n",
      "475:\tlearn: 0.0014760\ttest: 0.0038975\tbest: 0.0038975 (466)\ttotal: 1h 9m 45s\tremaining: 3m 31s\n",
      "476:\tlearn: 0.0014702\ttest: 0.0038902\tbest: 0.0038902 (476)\ttotal: 1h 9m 54s\tremaining: 3m 22s\n",
      "477:\tlearn: 0.0014616\ttest: 0.0038865\tbest: 0.0038865 (477)\ttotal: 1h 10m 3s\tremaining: 3m 13s\n",
      "478:\tlearn: 0.0014631\ttest: 0.0038865\tbest: 0.0038865 (477)\ttotal: 1h 10m 12s\tremaining: 3m 4s\n",
      "479:\tlearn: 0.0014631\ttest: 0.0038865\tbest: 0.0038865 (477)\ttotal: 1h 10m 21s\tremaining: 2m 55s\n",
      "480:\tlearn: 0.0014488\ttest: 0.0038865\tbest: 0.0038865 (477)\ttotal: 1h 10m 29s\tremaining: 2m 47s\n",
      "481:\tlearn: 0.0014431\ttest: 0.0038939\tbest: 0.0038865 (477)\ttotal: 1h 10m 38s\tremaining: 2m 38s\n",
      "482:\tlearn: 0.0014431\ttest: 0.0038975\tbest: 0.0038865 (477)\ttotal: 1h 10m 47s\tremaining: 2m 29s\n",
      "483:\tlearn: 0.0014345\ttest: 0.0038865\tbest: 0.0038865 (477)\ttotal: 1h 10m 56s\tremaining: 2m 20s\n",
      "484:\tlearn: 0.0014245\ttest: 0.0038828\tbest: 0.0038828 (484)\ttotal: 1h 11m 5s\tremaining: 2m 11s\n",
      "485:\tlearn: 0.0014202\ttest: 0.0038791\tbest: 0.0038791 (485)\ttotal: 1h 11m 13s\tremaining: 2m 3s\n",
      "486:\tlearn: 0.0014159\ttest: 0.0038791\tbest: 0.0038791 (485)\ttotal: 1h 11m 22s\tremaining: 1m 54s\n",
      "487:\tlearn: 0.0014087\ttest: 0.0038828\tbest: 0.0038791 (485)\ttotal: 1h 11m 31s\tremaining: 1m 45s\n",
      "488:\tlearn: 0.0014102\ttest: 0.0038828\tbest: 0.0038791 (485)\ttotal: 1h 11m 40s\tremaining: 1m 36s\n",
      "489:\tlearn: 0.0014102\ttest: 0.0038828\tbest: 0.0038791 (485)\ttotal: 1h 11m 49s\tremaining: 1m 27s\n",
      "490:\tlearn: 0.0014087\ttest: 0.0038828\tbest: 0.0038791 (485)\ttotal: 1h 11m 57s\tremaining: 1m 19s\n",
      "491:\tlearn: 0.0014087\ttest: 0.0038828\tbest: 0.0038791 (485)\ttotal: 1h 12m 6s\tremaining: 1m 10s\n",
      "492:\tlearn: 0.0014087\ttest: 0.0038828\tbest: 0.0038791 (485)\ttotal: 1h 12m 15s\tremaining: 1m 1s\n",
      "493:\tlearn: 0.0014087\ttest: 0.0038828\tbest: 0.0038791 (485)\ttotal: 1h 12m 24s\tremaining: 52.8s\n",
      "494:\tlearn: 0.0014073\ttest: 0.0038828\tbest: 0.0038791 (485)\ttotal: 1h 12m 33s\tremaining: 44s\n",
      "495:\tlearn: 0.0014016\ttest: 0.0038791\tbest: 0.0038791 (485)\ttotal: 1h 12m 41s\tremaining: 35.2s\n",
      "496:\tlearn: 0.0014016\ttest: 0.0038791\tbest: 0.0038791 (485)\ttotal: 1h 12m 50s\tremaining: 26.4s\n",
      "497:\tlearn: 0.0013959\ttest: 0.0038828\tbest: 0.0038791 (485)\ttotal: 1h 12m 59s\tremaining: 17.6s\n",
      "498:\tlearn: 0.0013973\ttest: 0.0038828\tbest: 0.0038791 (485)\ttotal: 1h 13m 8s\tremaining: 8.79s\n",
      "499:\tlearn: 0.0013973\ttest: 0.0038828\tbest: 0.0038791 (485)\ttotal: 1h 13m 17s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.003879135843\n",
      "bestIteration = 485\n",
      "\n",
      "Shrink model to first 486 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7facf04113d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = CatBoostClassifier(\n",
    "    loss_function='MultiLogloss',\n",
    "    eval_metric='HammingLoss',\n",
    "    iterations=500,\n",
    ")\n",
    "clf.fit(train_pool, eval_set=test_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d1d5d3-2ca1-429f-9018-e90af5988d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(test_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "806fa4eb-2f69-4d2d-8a9d-d26e9bc44ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.846732729748629\n",
      "Precision: 0.8325783266823347\n",
      "F1 Measure: 0.8327294875820876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyter/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(test_labels, pred_labels=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befbbf5f-94ad-4d19-a3e3-a7dcfa24910b",
   "metadata": {},
   "source": [
    "## 3.4 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad206add-3c74-47ee-87a6-6d84f909f5d7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyter/lib64/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:33:04] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:33:17] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:33:27] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:33:35] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:33:46] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:33:56] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:34:03] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:34:10] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:34:16] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:34:22] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:34:30] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:34:39] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:34:46] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:34:59] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:35:06] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:35:12] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:35:22] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:35:27] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:35:43] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:35:49] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:36:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:36:07] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:36:20] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:36:27] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:36:38] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:36:48] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:36:58] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:37:12] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:37:20] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:37:26] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:37:33] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:37:42] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:37:50] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:37:56] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:38:03] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:38:17] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:38:26] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:38:35] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:38:42] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:38:51] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:38:58] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:39:05] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:39:10] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:39:15] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:39:25] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:39:33] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:39:43] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:39:56] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:40:10] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:40:15] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:40:25] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:40:30] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:40:37] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:40:43] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:40:49] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:41:01] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:41:07] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:41:13] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:41:20] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:41:31] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:41:43] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:41:48] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:41:54] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:42:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:42:07] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:42:12] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:42:19] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:42:27] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:42:37] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:42:45] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:42:52] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:42:57] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:43:12] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:43:18] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:43:25] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:43:32] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:43:40] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:43:51] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:02] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:10] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:16] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:22] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:28] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:38] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:44] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:59] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:45:08] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:45:19] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:45:27] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:45:38] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Precision: 0.881411378728371, \n",
      " Recall: 0.8769964945436955, \n",
      " F1 Measure: 0.8710263168712598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyter/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "xgb_estimator = xgb.XGBClassifier(objective='binary:logistic')\n",
    "multilabel_model = MultiOutputClassifier(xgb_estimator)\n",
    "multilabel_model.fit(vectors[\"train\"], train_labels)\n",
    "predictions = multilabel_model.predict(vectors[\"test\"])\n",
    "calculate_metrics(test_labels, pred_labels=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99321339-b629-462a-a086-9778075ada25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7769x26147 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 459175 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fffa0fbe-9949-4e42-b7bb-ac946937cdac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7769x26147 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 459175 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79f61223-9b4b-404f-b674-00abb256f912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "              validate_parameters=None, verbosity=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5a261b-c2a7-4f22-82a0-489597b256d7",
   "metadata": {},
   "source": [
    "# 4. Model saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18044525-e28c-4370-b0b1-5512dbca5179",
   "metadata": {},
   "source": [
    "## 4.1 Using ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f9aace-bba7-4cd9-803d-6c6a19e1d671",
   "metadata": {},
   "source": [
    "ONNX is a good option since the ONNX model checkpoint can be used with different programming languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a606ece4-1c15-4643-b659-934e5fac8fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx import convert_sklearn, update_registered_converter\n",
    "from skl2onnx.common.shape_calculator import calculate_linear_classifier_output_shapes  # noqa\n",
    "from skl2onnx import to_onnx\n",
    "from onnxmltools.convert.xgboost.operator_converters.XGBoost import convert_xgboost  # noqa\n",
    "import onnxruntime as rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4dcae31-4e61-4867-83bd-c4434221c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_registered_converter(\n",
    "    xgb.XGBClassifier, 'XGBoostXGBClassifier',\n",
    "    calculate_linear_classifier_output_shapes, convert_xgboost,\n",
    "    options={'nocl': [True, False], 'zipmap': [True, False, 'columns']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583aee27-d3ee-433b-9990-5739d0e40ed8",
   "metadata": {},
   "source": [
    "### First method of saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c75b77bf-de89-49cb-a7d4-0b7266614665",
   "metadata": {},
   "outputs": [],
   "source": [
    "onx5 = to_onnx(multilabel_model, vectors[\"train\"].todense().astype(np.float32), target_opset=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa23aca9-bc56-46df-ab32-6534870b7dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = vectors[\"test\"].todense()\n",
    "\n",
    "sess5 = rt.InferenceSession(onx5.SerializeToString())\n",
    "res5 = sess5.run(None, {'X': a.astype(np.float32)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db3f6193-39ec-4271-a5b0-3fbece58f59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0635719649960213, \n",
      " Recall: 0.6201468979292761, \n",
      " F1 Measure: 0.11263173402239948\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(test_labels, pred_labels=res5[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a996dfe-514f-4736-95df-01f8cbc21f2b",
   "metadata": {},
   "source": [
    "### Second method of saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "92adeec2-1c71-40db-ac66-14cc89a556d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_onnx = convert_sklearn(\n",
    "    multilabel_model, 'pipeline_xgboost',\n",
    "    [('input', FloatTensorType([None, 26147]))],\n",
    ")\n",
    "\n",
    "with open(\"pipeline_xgboost.onnx\", \"wb\") as f:\n",
    "    f.write(model_onnx.SerializeToString())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d240d267-42ff-4b65-9d61-c36ee67d0b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = vectors[\"test\"].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "91c2a0aa-4244-4f3f-bfce-7ed9788eba1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "predict_proba [array([[0.9886203 , 0.01137972],\n",
      "       [0.915495  , 0.08450502],\n",
      "       [0.9667655 , 0.03323448],\n",
      "       ...,\n",
      "       [0.98589504, 0.01410496],\n",
      "       [0.9899721 , 0.01002789],\n",
      "       [0.93870187, 0.06129813]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "sess = rt.InferenceSession(\"pipeline_xgboost.onnx\")\n",
    "pred_onx = sess.run(None, {\"input\": a.astype(np.float32)})\n",
    "print(\"predict\", pred_onx[0])\n",
    "print(\"predict_proba\", pred_onx[1][:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3d093917-1f6c-45de-9824-a545a9b0fc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0635719649960213, \n",
      " Recall: 0.6201468979292761, \n",
      " F1 Measure: 0.11263173402239948\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(test_labels, pred_labels=pred_onx[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e5fa78-86b0-4cf4-929a-c444c72edc2c",
   "metadata": {},
   "source": [
    "I see that the output ONNX checkpoint for our model doesn't work as expected. Will use the classic method of saving via joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dc06ff0d-7164-4d09-83e3-ba3f075aa634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgboost']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(multilabel_model, \"xgboost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e582e8-ab2c-45a3-81f7-ac02234d332c",
   "metadata": {},
   "source": [
    "Testing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f4ac615-7345-4829-8a59-9e292eb2f2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_test = joblib.load('xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81f0d254-b551-4c74-b3ef-217d1b147299",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = classifier_test.predict(vectors[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fc79680-ba36-48b0-a777-025319359846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.881411378728371, \n",
      " Recall: 0.8769964945436955, \n",
      " F1 Measure: 0.8710263168712598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyter/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(test_labels, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fceaa09-374f-408e-8093-8474eb45bc26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
